{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded from https://www.kaggle.com/datasets/oddrationale/mnist-in-csv?resource=download\n",
    "mnistTraining = \"/Users/christianjohnson/Downloads/net/SimpleNeuralNet/mnist_train.csv\"\n",
    "mnistTest = \"/Users/christianjohnson/Downloads/net/SimpleNeuralNet/mnist_test.csv\"\n",
    "data = pd.read_csv(mnistTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayData = np.array(data)\n",
    "# m - number of training images\n",
    "# n - label + intensity values of each pixel (28x28)\n",
    "m, n = arrayData.shape\n",
    "\n",
    "# shuffle data\n",
    "np.random.shuffle(arrayData)\n",
    "\n",
    "# initialize the dev set (first 1000 rows) and transpose\n",
    "devSet = arrayData[:1000].T\n",
    "# seperate labels and values of the dev set\n",
    "devLabels = devSet[0]\n",
    "devVals = devSet[1:n] / 255. # normalizing values between 0 and 1\n",
    "\n",
    "# initialize the training set [1000:] rows and transpose\n",
    "tSet = arrayData[1000:].T\n",
    "# seperate labels and values of the training set\n",
    "tLabels = tSet[0]\n",
    "tVals = tSet[1:n] / 255. # normalizing values between 0 and 1\n",
    "\n",
    "tRows, tCols = tVals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights and baises\n",
    "def initalization():\n",
    "    w1 = np.random.rand(10,784) - 0.5\n",
    "    b1 = np.random.rand(10,1) - 0.5\n",
    "    w2 = np.random.rand(10,10) - 0.5\n",
    "    b2 = np.random.rand(10,1) - 0.5\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "# reLu activation function\n",
    "def reLu(x):\n",
    "    np.maximum(x, 0)\n",
    "\n",
    "def sigmoind(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    #return np.abs(x)\n",
    "\n",
    "def sigmoidDerivative(x):\n",
    "    return sigmoind(x) * (1 - sigmoind(x))\n",
    "    \n",
    "\n",
    "# softMax function\n",
    "def softMax(x):\n",
    "    return np.exp(x) / sum(np.exp(x))\n",
    "    #return np.abs(x) / sum(np.abs(x))\n",
    "\n",
    "# Forward Propagation\n",
    "def forwardPropagation(w1, b1, w2, b2, x):\n",
    "    A0 = x\n",
    "    Z1 = np.dot(w1,A0) + b1\n",
    "    A1 = sigmoind(Z1)\n",
    "    Z2 = np.dot(w2,A1) + b2\n",
    "    A2 = softMax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# derivative of the ReLu function (see reLu graph in neuralNetNotes.pdf)\n",
    "def reLuDerivative(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "# One hot Y encoding\n",
    "def oneHotY(Y):\n",
    "    oneHot = np.zeros((Y.size,Y.max() + 1))\n",
    "    oneHot[np.arange(Y.size),Y] = 1\n",
    "    return oneHot.T\n",
    "\n",
    "# Backwards Propagation\n",
    "def backPropagation(z1, a1, w2, a2, x, y):\n",
    "    one_hot = oneHotY(y)\n",
    "    dz2 = a2 - one_hot \n",
    "    dw2 = np.dot(dz2, a1.T) * 1/m\n",
    "    db2 = sum(dz2)\n",
    "    dz1 = np.dot(w2.T, dz2) * sigmoidDerivative(z1)\n",
    "    dw1 = np.dot(dz1, x.T)\n",
    "    db1 = sum(dz1)\n",
    "    return dw1, db1, dw2, db2\n",
    "\n",
    "def updatedWeights(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha):\n",
    "    w1 = w1 - alpha * dw1\n",
    "    b1 = b1 - alpha * db1\n",
    "    w2 = w2 - alpha * dw2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "def gradientDescent(X, Y, alpha, iter):\n",
    "    w1, b1, w2, b2 = initalization()\n",
    "    for i in range(iter):\n",
    "        Z1, A1, Z2, A2 = forwardPropagation(w1, b1, w2, b2, X)\n",
    "        dw1, db1, dw2, db2 = backPropagation(Z1, A1, w2, A2, X, Y)\n",
    "        w1, b1, w2, b2 = updatedWeights(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)\n",
    "        if i % 100 == 0:\n",
    "            #print(\"Iteration: \", i)\n",
    "            predict = predictions(A2)\n",
    "            print(accuracy(predict, Y))\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "def predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
